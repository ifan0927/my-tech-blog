---
title: "N8N Automation Workflow for Hugo Content Generation"
date: "2025-11-25T00:00:00Z"
tags: ["n8n", "automation", "hugo", "claude", "workflow", "docker"]
categories: ["automation", "content-management"]
---

Today's focus was on building an automated workflow using N8N to streamline the daily note generation process for Hugo static site. The goal was to eliminate manual steps in converting AI-processed development notes into published Hugo posts.

## Project Overview

The main challenge was the repetitive manual process of taking daily development notes, processing them through AI (Claude), and then manually creating Hugo posts and pushing to GitHub. This workflow aimed to automate the entire pipeline from local note files to published content.

## Docker Configuration

Set up N8N using Docker with volume mapping to access local note files:

```yaml
version: '3'
services:
  n8n:
    image: n8nio/n8n
    ports:
      - "5678:5678"
    volumes:
      - ~/.n8n:/home/node/.n8n
      - /Users/cheni-fan/n8n:/files
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=password
```

The key aspect is the volume mapping (`/Users/cheni-fan/n8n:/files`) which allows N8N's read file node to access local development notes. A code node handles date-based file selection to grab the current day's notes.

## N8N Workflow Architecture

The workflow consists of three main components:

1. **File Reading**: Read file node retrieves daily notes from mapped volume
2. **AI Processing**: Anthropic node sends content to Claude for refinement
3. **Content Processing**: Code node handles text formatting and metadata extraction
4. **GitHub Integration**: GitHub node handles file creation and commit

## Content Processing Logic

The core text processing handles several formatting tasks:

```javascript
// Get input data
const inputData = $input.item.json;
let content = inputData.content[0].text;

// 1. Remove  tags
content = content.replace(/<\/?markdown_output>/g, '');

// 2. Convert 
 strings to actual line breaks
content = content.replace(/\
/g, '
');

// 3. Clean whitespace
content = content.trim();

// 4. Extract metadata from frontmatter
const dateMatch = content.match(/date:\s*"?(\d{4}-\d{2}-\d{2})/);
const titleMatch = content.match(/title:\s*"([^"]+)"/);

// 5. Generate filename (slug)
let fileName = '';
if (dateMatch && titleMatch) {
  const date = dateMatch[1];
  fileName = `${date}_Note.md`;
} else {
  // Fallback: use timestamp
  const timestamp = new Date().toISOString().split('T')[0];
  fileName = `${timestamp}-post.md`;
}

// 6. Set file path
const filePath = `content/posts/${fileName}`;

// 7. Prepare commit message
const commitMessage = titleMatch 
  ? `Add post: ${titleMatch[1]}` 
  : `Add new post: ${fileName}`;

// 8. Output for GitHub node
return {
  json: {
    fileContent: content,
    filePath: filePath,
    commitMessage: commitMessage,
    fileName: fileName
  }
};
```

## Key Technical Features

- **Dynamic file naming**: Extracts date and title from frontmatter to generate consistent filenames
- **Text formatting**: Handles markdown tag cleanup and proper line break conversion
- **Automated Git operations**: Generates meaningful commit messages and pushes to repository
- **Error handling**: Fallback filename generation if metadata extraction fails

## Results

Successfully automated the complete pipeline from local development notes to published Hugo content, eliminating manual file creation, editing, and Git operations. The workflow now handles the entire process from AI content refinement through to GitHub deployment.

## Next Steps

Consider adding error handling for failed API calls and implementing notification mechanisms for workflow completion status.